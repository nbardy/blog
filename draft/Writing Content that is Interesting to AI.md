# Writing Content that is Interesting to AI (Superhuman Questions)

Inspired by watching a video of Tyler Cowen and his incessant desire to "write for AI." More and more, this question occupies my mind. Besides using ChatGPT more often, what can we really do to make more use of AI? Tyler Cowen suggests, "Write for AI." More pointedly, in this recent interview he says, ["modify your writing to make it more interesting for AI"](https://www.youtube.com/watch?v=t6Je8EKhUyw). As Tyler Cowen usually is—terse, brilliant, and almost undecipherable.

Let's see what the hell that could even mean...

Being an over-obsessed lunatic who has given his autonomy to ChatGPT and is forcibly struggling to think or write for myself anymore... You know what, fuck it. Let's just ask the AI.

<img width="548" alt="image" src="https://github.com/user-attachments/assets/c37ff63b-9101-4b54-a54c-39da06450b7b" />

Thoughts:

<img width="846" alt="image" src="https://github.com/user-attachments/assets/66f1ba89-83d5-496d-8638-83d1cd53a5a8" />

The thoughts are pretty raw and hard to interpret, but luckily, we can just ask to make it actionable.

<img width="796" alt="image" src="https://github.com/user-attachments/assets/1ac2213a-19f7-4e7d-b6cd-406bc0edc943" />

Still a little esoteric for my taste, but kind of interesting. However, for the life of me, I can't think of how to do any of these things and how to actually write something "Interesting for AI." Well... Maybe instead of writing... Yeah fuck it again. Let's just ask for examples.

<img width="573" alt="image" src="https://github.com/user-attachments/assets/302ed41f-8930-4d37-a0d4-93c659f776bc" />

And... It starts to let us know. Each list was pretty similar, so I cherry-picked some of the more clear and interesting examples below.

## #1 - Not Interesting
<img width="786" alt="image" src="https://github.com/user-attachments/assets/fe0c60f7-1bd1-482b-83b7-98defa248a02" />

## #2 - Appears Interesting, but Actually Boring
Appears Interesting, but Actually Boring (Flashy or Complex-Looking yet Trivial)
<img width="778" alt="image" src="https://github.com/user-attachments/assets/622aa274-05d0-4341-b097-5ac6f1a11dc2" />

## #3 - Appears Boring, but Actually Interesting
<img width="784" alt="image" src="https://github.com/user-attachments/assets/f885f9a9-09c6-4a5e-9a0c-2beda325674f" />
<img width="785" alt="image" src="https://github.com/user-attachments/assets/27a59593-8532-48dc-9ce4-6ac50d44a6bd" />

<img width="755" alt="image" src="https://github.com/user-attachments/assets/4e0cf322-3595-457d-96ac-502be086005d" />

## #4 - Interesting
<img width="786" alt="image" src="https://github.com/user-attachments/assets/c1d0f4eb-06e3-4935-8e9c-81fdc4d169a5" />
<img width="786" alt="image" src="https://github.com/user-attachments/assets/fa547f2c-c31a-4c35-bc1e-0d0808de9cfa" />

It continues on: The Ship of Theseus, the Halting Problem, even... The Trolley Problem.

So, to write something interesting for AI we just need to write something that is... A novel enduring philosophical puzzle to rival ideas as old and profound as the books of history itself. Man's search for meaning simply requires unparalleled greatness.

Well, actually wait a second—what if we just ask the AI again?

<img width="776" alt="image" src="https://github.com/user-attachments/assets/6ee0058b-6be2-499a-8db8-94a09ac1fd46" />

Honestly kind of interesting, and I've never been able to come up with a paradox like this myself. So is this interesting to AI? And did we actually write it?

Turns out, sort of. This sort of self-referential paradox has been well defined in philosophy.

<img width="798" alt="image" src="https://github.com/user-attachments/assets/13decacc-bbd1-4ca0-b956-a4f67f9a53fd" />

Well, that opens up perhaps a more interesting question: "Can content that comes out of an AI model be new or surprising?" Given it's sampling from a model of high likelihood, the answer is yes—because the human is still injecting direction and steering the model. Every time you adjust a prompt, you have an opportunity to move a model away from its expected output. An AI prompted in a novel direction creates content that is novel from the training data. We can maintain the "rules and order" implied by the model weights while still shifting the distribution of the output to something unique.

Perhaps this is a brief window that is closing. As AIs become better at self-direction, how much does it even matter what we ask for or how we ask for it?

According to thinking models like R1, maybe not. This model is trained on a reflection of its own thoughts. Initially, the thoughts fail—but examining piles of failed and unfailed thoughts eventually it transcends its own capacity, merely through reflection on its own failure and self-direction.

However, I don't see this as a doom loop. Because even a self-directed AI needs a starting point. The prompts may become smaller and simpler, but they'll still be relevant. And then, as they become more agentic, being able to check in and analyze what they are doing becomes more important.

And what's the best way to ask a question? Give it to another agent. Pass the small dense framework of your required evaluation for human/product/societal alignment. And let the agent execute the reading and probing of the self-directed agent already working on the problem. As the frequency of checking in with AI goes down and their task horizon goes up, the value of each check-in rises drastically.

## Learn to Ask AI Super-human Questions

This all wraps up to my final point. Our new overlords—the Orwellian LLMs—are here to observe our every thought and complete our every action in almost instantaneous time. They will be smarter, faster, collaborate more seamlessly, and parallelize better than us. They will be superhuman. However, what use is a superhuman without superhuman questions? Learning to ask questions that you yourself could never answer becomes the new superpower.

The only trick I’ve found to asking superhuman questions is to consume lots of mathematics and research and look for combinations of ideas that are **compatible** but have not been used together yet.

For example in geometry:  
The "Menger Cube" and the "hypercube." Both are cubes, one is 4D, one is 3D. Turns out the AI can make the Menger Hypercube—a Menger cube in 4D.

## What have I been doing with AI?

There are only a few categories where I know enough to ask for things that don't exist yet: Geometry and Computer Science. In both of these things, I have managed to achieve feats that I myself was not able to do alone:

1) Render higher dimensional objects ([4D Spheres / S3, Menger hypercube, etc...](https://www.shadertoy.com/view/MXtBWs))  
2) Write a programming language with compiler and interpreter (My first one here: [SynesthesiaLisp](https://github.com/nbardy/SynesthesiaLisp); another DSL here for doing math with LLM: [MTCS](https://github.com/NeoVertex1/SuperPrompt/blob/main/CTMS.md); and two more as internal research projects at both Adobe and LeonardoAI)

In both cases, these are tasks that *I could have* done alone given my past experience, but the scope of the projects would have been so much narrower—or required assistance from another engineer. Instead, I was able to build a functional version in days rather than months.

Writing programming languages:  
`SuperPrompt` — Note: I have also done this many times.

Check out [my Shadertoy collection](https://www.shadertoy.com/profile/?show=shaders)
